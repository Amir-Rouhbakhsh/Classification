{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to your training and testing datasets\n",
    "train_data_dir = \"C:/Users/Amir/Desktop/skin cancer paper/skin cancer isic/Skin Cancer ISIC/Skin cancer ISIC The International Skin Imaging Collaboration/train\"  # Replace with the path to your training dataset\n",
    "test_data_dir = \"C:/Users/Amir/Desktop/skin cancer paper/skin cancer isic/Skin Cancer ISIC/Skin cancer ISIC The International Skin Imaging Collaboration/test\"  # Replace with the path to your testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c0dd13c82f43118b8f41f28c8e5c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amir\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Amir\\.cache\\huggingface\\hub\\models--google--vit-base-patch16-224. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\Amir\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the ViT feature extractor\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Define transformations for the images\n",
    "def preprocess_image(image):\n",
    "    return feature_extractor(image, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04a4cdcc98145f6ac1f7d112504fd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f2ec05a99c4aaf8f325488f789148d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([9]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([9, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(train_data_dir, transform=preprocess_image)\n",
    "test_dataset = datasets.ImageFolder(test_data_dir, transform=preprocess_image)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the pre-trained ViT model\n",
    "num_classes = len(train_dataset.classes)  # Number of classes in your dataset\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Training: 100%|██████████| 70/70 [01:34<00:00,  1.35s/it, accuracy=58.2, loss=0.765]\n",
      "Epoch [1/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.92s/it, accuracy=56.8, loss=2.35] \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.2060, Train Accuracy: 58.15%, Val Loss: 1.4930, Val Accuracy: 56.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Training: 100%|██████████| 70/70 [01:36<00:00,  1.38s/it, accuracy=77.1, loss=0.77] \n",
      "Epoch [2/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it, accuracy=63.6, loss=1.54] \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 0.6203, Train Accuracy: 77.13%, Val Loss: 1.2814, Val Accuracy: 63.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Training: 100%|██████████| 70/70 [01:36<00:00,  1.37s/it, accuracy=85.9, loss=0.207]\n",
      "Epoch [3/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it, accuracy=59.3, loss=1.03] \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 0.3417, Train Accuracy: 85.93%, Val Loss: 1.2436, Val Accuracy: 59.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Training: 100%|██████████| 70/70 [01:36<00:00,  1.37s/it, accuracy=90.2, loss=0.444] \n",
      "Epoch [4/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it, accuracy=57.6, loss=1.91] \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 0.2307, Train Accuracy: 90.22%, Val Loss: 1.8088, Val Accuracy: 57.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Training: 100%|██████████| 70/70 [01:35<00:00,  1.37s/it, accuracy=90.5, loss=0.412] \n",
      "Epoch [5/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it, accuracy=59.3, loss=2.3]  \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 0.2178, Train Accuracy: 90.53%, Val Loss: 1.6287, Val Accuracy: 59.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Training: 100%|██████████| 70/70 [01:37<00:00,  1.39s/it, accuracy=92.9, loss=0.206] \n",
      "Epoch [6/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.89s/it, accuracy=61, loss=2.01]    \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 0.1494, Train Accuracy: 92.85%, Val Loss: 1.6550, Val Accuracy: 61.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Training: 100%|██████████| 70/70 [01:37<00:00,  1.39s/it, accuracy=92.1, loss=0.104]  \n",
      "Epoch [7/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it, accuracy=63.6, loss=1.87]  \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 0.1283, Train Accuracy: 92.09%, Val Loss: 1.7791, Val Accuracy: 63.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Training: 100%|██████████| 70/70 [01:37<00:00,  1.39s/it, accuracy=92.1, loss=0.172] \n",
      "Epoch [8/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.90s/it, accuracy=61, loss=1.7]    \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Train Loss: 0.1173, Train Accuracy: 92.05%, Val Loss: 1.7811, Val Accuracy: 61.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Training: 100%|██████████| 70/70 [01:37<00:00,  1.40s/it, accuracy=93.1, loss=0.265]  \n",
      "Epoch [9/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.90s/it, accuracy=64.4, loss=1.51] \n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Train Loss: 0.1205, Train Accuracy: 93.08%, Val Loss: 1.8923, Val Accuracy: 64.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] Training: 100%|██████████| 70/70 [01:37<00:00,  1.39s/it, accuracy=89.5, loss=0.368] \n",
      "Epoch [10/10] Validation: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it, accuracy=59.3, loss=1.68] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Train Loss: 0.2199, Train Accuracy: 89.55%, Val Loss: 1.8227, Val Accuracy: 59.32%\n",
      "Training metrics saved to training_metrics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Amir\\AppData\\Local\\Temp\\ipykernel_17680\\3807495128.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  metrics_df = metrics_df.append({\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize a DataFrame to store metrics\n",
    "metrics_df = pd.DataFrame(columns=[\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Val Loss\", \"Val Accuracy\"])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Wrap train_loader with tqdm for a progress bar\n",
    "    train_loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Training\")\n",
    "    for images, labels in train_loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track metrics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update the progress bar description\n",
    "        train_loop.set_postfix(loss=loss.item(), accuracy=(correct / total) * 100)\n",
    "\n",
    "    # Compute training metrics\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    # Wrap val_loader with tqdm for a progress bar\n",
    "    val_loop = tqdm(test_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}] Validation\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Track metrics\n",
    "            val_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update the progress bar description\n",
    "            val_loop.set_postfix(loss=loss.item(), accuracy=(val_correct / val_total) * 100)\n",
    "\n",
    "    # Compute validation metrics\n",
    "    val_loss = val_running_loss / len(test_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "    # Print epoch metrics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save metrics to DataFrame\n",
    "    metrics_df = metrics_df.append({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": train_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Val Loss\": val_loss,\n",
    "        \"Val Accuracy\": val_accuracy\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Save metrics to a CSV file\n",
    "metrics_df.to_csv(\"training_metrics.csv\", index=False)\n",
    "print(\"Training metrics saved to training_metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
